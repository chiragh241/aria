"""Config writer that generates settings.yaml and .env from wizard state."""

from __future__ import annotations

import shutil
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any

import yaml

if TYPE_CHECKING:
    from src.cli.wizard import WizardState

from src.cli.steps.llm import NVIDIA_DEFAULT_MODEL


class ConfigWriter:
    """Generates configuration files from wizard state."""

    def __init__(self, state: WizardState, project_root: Path | None = None):
        self.state = state
        self.root = project_root or Path(".")
        self.config_dir = self.root / "config"
        self.data_dir = self.root / "data"

    def write_all(self) -> list[str]:
        """Write all configuration files. Returns list of written file paths."""
        written: list[str] = []

        # Ensure directories exist
        self.config_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # Back up existing files
        self._backup_if_exists(self.config_dir / "settings.yaml")
        self._backup_if_exists(self.root / ".env")

        # Write settings.yaml
        settings_path = self.config_dir / "settings.yaml"
        self._write_settings_yaml(settings_path)
        written.append(str(settings_path))

        # Write .env
        env_path = self.root / ".env"
        self._write_env(env_path)
        written.append(str(env_path))

        # Write sentinel file
        sentinel = self.data_dir / ".aria_configured"
        sentinel.write_text(
            f"configured_at: {datetime.now().isoformat()}\n"
            f"version: 0.1.0\n"
        )
        written.append(str(sentinel))

        # Reset user data so first-time setup starts fresh (chat history, memory, etc.)
        self._reset_user_data()

        return written

    def _reset_user_data(self) -> None:
        """Remove persisted chat history, memory, user profiles, and DB so new setup starts fresh."""
        paths_to_remove = [
            self.data_dir / "conversations",   # Chat/conversation history
            self.data_dir / "chromadb",       # Long-term vector memory
            self.data_dir / "cognee",         # Knowledge graph (cognee)
            self.data_dir / "user_profiles",  # User names / preferences (first-time intro after setup)
        ]
        file_to_remove = self.data_dir / "aria.db"  # SQLite DB (episodic + app state)

        for path in paths_to_remove:
            if path.exists():
                try:
                    shutil.rmtree(path)
                except OSError:
                    pass  # Ignore permission or in-use errors

        if file_to_remove.exists():
            try:
                file_to_remove.unlink(missing_ok=True)
            except OSError:
                pass

    # ── settings.yaml ──────────────────────────────────────────────────────

    def _write_settings_yaml(self, path: Path) -> None:
        """Generate and write the settings.yaml file."""
        config = self._build_settings_dict()

        header = (
            "# Aria Personal AI Agent Configuration\n"
            f"# Generated by setup wizard on {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
            "# Edit manually or re-run: python -m src.main --setup\n\n"
        )

        with open(path, "w") as f:
            f.write(header)
            yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)

    def _build_settings_dict(self) -> dict[str, Any]:
        """Build the full settings dictionary from wizard state."""
        s = self.state
        config: dict[str, Any] = {}

        # aria
        config["aria"] = {
            "name": "Aria",
            "version": "0.1.0",
            "data_dir": "./data",
            "deployment_mode": s.deployment_mode,
        }

        # llm
        config["llm"] = self._build_llm_config()

        # channels
        config["channels"] = self._build_channels_config()

        # security
        config["security"] = {
            "active_profile": s.security_profile,
            "approval_timeout": 300,
            "approval_channels": self._build_approval_channels(),
            "require_all_approvals": False,
        }

        # sandbox
        config["sandbox"] = self._build_sandbox_config()

        # memory
        config["memory"] = {
            "short_term": {
                "max_messages": 50,
                "max_tokens": 8000,
                "max_tool_result_chars": 4000,
                "use_proportional_tool_result": True,
                "max_tool_result_chars_at_persist": 400_000,
                "max_turns": 0,
                "compaction_reserve_tokens": 20_000,
                "compaction_trigger_tokens": 0,
            },
            "long_term": {
                "provider": "chromadb",
                "persist_directory": "./data/chromadb",
                "collection_name": "aria_memory",
                "embedding_model": "all-MiniLM-L6-v2",
            },
            "episodic": {"max_episodes": 1000, "summary_threshold": 10},
            "knowledge_graph": {
                "enabled": True,
                "provider": "cognee",
                "auto_process_after_ingest": True,
            },
            "rag_max_chars": 2500,
            "rag_head_ratio": 0.7,
            "rag_tail_ratio": 0.2,
            "user_profiles_enabled": True,
            "entity_extraction_enabled": True,
            "auto_summarize": True,
        }

        # database
        config["database"] = {
            "url": "sqlite+aiosqlite:///./data/aria.db",
            "echo": False,
        }

        # redis
        config["redis"] = {"enabled": False, "url": "redis://localhost:6379/0"}

        # logging
        config["logging"] = {
            "level": "INFO",
            "format": "json",
            "file": "./data/logs/aria.log",
            "max_size_mb": 100,
            "backup_count": 5,
            "audit_file": "./data/logs/audit.log",
        }

        # skills
        config["skills"] = self._build_skills_config()

        # dashboard
        config["dashboard"] = {
            "title": "Aria Control Center",
            "theme": "dark",
            "features": {
                "chat": True,
                "approvals": True,
                "settings": True,
                "logs": True,
                "skills": True,
                "metrics": True,
            },
        }

        # orchestrator (more tool iterations = finish more tasks in one turn)
        config["orchestrator"] = {"max_tool_iterations": 15}

        # workspace (SOUL.md, USER.md, AGENTS.md, IDENTITY.md injected into system prompt)
        config["workspace"] = {
            "enabled": True,
            "path": "./data/workspace",
            "max_injected_chars": 32_768,
            "bootstrap_on_first_run": True,
        }

        # onecontext — unified context across all channels
        config["onecontext"] = {
            "enabled": "onecontext" in getattr(s, "enabled_skills", []),
            "working_path": "./data/aria_workspace",
            "sync_on_agent_complete": True,
        }

        return config

    def _build_llm_config(self) -> dict[str, Any]:
        """Build LLM configuration section."""
        s = self.state
        llm: dict[str, Any] = {}

        # Local LLM
        local_enabled = s.llm_provider in ("ollama", "hybrid") and s.ollama_enabled
        llm["local"] = {
            "provider": "ollama",
            "model": s.ollama_model,
            "base_url": s.ollama_base_url,
            "timeout": 60,
            "enabled": local_enabled,
        }

        # Cloud LLM (Anthropic)
        cloud_enabled = s.llm_provider in ("anthropic", "hybrid")
        llm["cloud"] = {
            "provider": "anthropic",
            "model": s.anthropic_model,
            "max_tokens": 4096,
            "timeout": 120,
            "enabled": cloud_enabled,
        }

        # Gemini
        llm["gemini"] = {
            "provider": "gemini",
            "model": getattr(s, "gemini_model", "gemini-2.0-flash"),
            "max_tokens": 4096,
            "timeout": 120,
            "enabled": s.llm_provider == "gemini",
        }

        # OpenRouter
        llm["openrouter"] = {
            "provider": "openrouter",
            "model": getattr(s, "openrouter_model", "anthropic/claude-3.5-sonnet"),
            "max_tokens": 4096,
            "timeout": 120,
            "enabled": s.llm_provider == "openrouter",
            "use_free_models": getattr(s, "openrouter_use_free", False),
        }

        # NVIDIA NIM
        llm["nvidia"] = {
            "provider": "nvidia",
            "model": getattr(s, "nvidia_model", NVIDIA_DEFAULT_MODEL),
            "max_tokens": 16384,
            "timeout": 120,
            "enabled": s.llm_provider == "nvidia",
        }

        # Routing
        any_cloud = cloud_enabled or s.llm_provider in ("gemini", "openrouter", "nvidia")
        llm["routing"] = {
            "simple_threshold": 50,
            "always_cloud": [
                "code_generation",
                "complex_reasoning",
                "skill_creation",
                "multi_step_planning",
            ],
            "fallback_to_cloud": any_cloud,
        }

        return llm

    def _build_channels_config(self) -> dict[str, Any]:
        """Build channels configuration section."""
        s = self.state
        channels: dict[str, Any] = {}

        # Slack
        channels["slack"] = {
            "enabled": s.channels_slack,
            "bot_token": "${SLACK_BOT_TOKEN}",
            "app_token": "${SLACK_APP_TOKEN}",
            "allowed_channels": [],
        }

        # WhatsApp
        channels["whatsapp"] = {
            "enabled": s.channels_whatsapp,
            "session_path": "./data/whatsapp-session",
            "bridge_port": s.whatsapp_bridge_port,
            "bridge_host": "localhost",
            "allowed_numbers": s.whatsapp_allowed_numbers,
        }

        # Web
        channels["web"] = {
            "enabled": True,
            "host": "0.0.0.0",
            "port": s.dashboard_port,
            "jwt_secret": "${JWT_SECRET}",
            "jwt_expiry_hours": 24,
        }

        return channels

    def _build_sandbox_config(self) -> dict[str, Any]:
        """Build sandbox configuration section."""
        s = self.state
        sandbox: dict[str, Any] = {
            "default": "docker" if s.sandbox_mode == "docker" else "direct",
        }

        sandbox["docker"] = {
            "image": "aria-sandbox:latest",
            "memory_limit": s.docker_memory,
            "cpu_limit": s.docker_cpu,
            "network_mode": "none",
            "timeout": 300,
        }

        sandbox["trusted_paths"] = s.trusted_paths
        sandbox["safe_commands"] = ["ls", "pwd", "whoami", "date", "echo"]

        return sandbox

    def _build_skills_config(self) -> dict[str, Any]:
        """Build skills configuration section."""
        s = self.state

        builtin: dict[str, Any] = {
            "filesystem": {
                "enabled": "filesystem" in s.enabled_skills,
                "max_file_size_mb": 100,
            },
            "shell": {
                "enabled": "shell" in s.enabled_skills,
                "timeout": 60,
            },
            "browser": {
                "enabled": "browser" in s.enabled_skills and s.browser_mode != "none",
                "mode": getattr(s, "browser_mode", "playwright"),
                "headless": True,
                "timeout": 30,
            },
            "calendar": {"enabled": "calendar" in s.enabled_skills},
            "email": {"enabled": "email" in s.enabled_skills},
            "sms": {"enabled": "sms" in s.enabled_skills},
            "tts": {
                "enabled": "tts" in s.enabled_skills,
                "provider": "edge-tts",
                "voice": "en-US-AriaNeural",
            },
            "stt": {
                "enabled": "stt" in s.enabled_skills,
                "provider": "whisper",
                "model": "base",
            },
            "image": {"enabled": "image" in s.enabled_skills},
            "video": {
                "enabled": "video" in s.enabled_skills,
                "ffmpeg_path": "ffmpeg",
            },
            "documents": {"enabled": "documents" in s.enabled_skills},
            "memory": {"enabled": "memory" in s.enabled_skills},
            "weather": {"enabled": "weather" in s.enabled_skills},
            "news": {"enabled": "news" in s.enabled_skills},
            "finance": {"enabled": "finance" in s.enabled_skills},
            "contacts": {"enabled": "contacts" in s.enabled_skills},
            "tracking": {"enabled": "tracking" in s.enabled_skills},
            "home": {"enabled": "home" in s.enabled_skills},
            "webhook": {"enabled": "webhook" in s.enabled_skills},
            "agent": {"enabled": "agent" in s.enabled_skills},
            "research": {"enabled": "research" in s.enabled_skills},
            "notion": {"enabled": "notion" in s.enabled_skills, "api_key": ""},
            "todoist": {"enabled": "todoist" in s.enabled_skills, "api_key": ""},
            "linear": {"enabled": "linear" in s.enabled_skills, "api_key": ""},
            "spotify": {"enabled": "spotify" in s.enabled_skills, "client_id": "", "client_secret": ""},
        }

        return {
            "builtin": builtin,
            "learned": {
                "enabled": True,
                "directory": "./data/learned_skills",
                "auto_test": True,
                "require_approval": True,
            },
        }

    def _build_approval_channels(self) -> list[str]:
        """Build list of approval channels based on enabled channels."""
        channels = ["web"]
        if self.state.channels_slack:
            channels.append("slack")
        if self.state.channels_whatsapp:
            channels.append("whatsapp")
        return channels

    # ── .env ───────────────────────────────────────────────────────────────

    def _write_env(self, path: Path) -> None:
        """Generate and write the .env file."""
        s = self.state
        lines = [
            "# Aria Environment Variables",
            f"# Generated by setup wizard on {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "",
        ]

        # LLM
        lines.append("# LLM Configuration")
        if s.llm_provider in ("ollama", "hybrid"):
            lines.append(f"OLLAMA_HOST={s.ollama_base_url}")

        if s.anthropic_api_key:
            lines.append(f"ANTHROPIC_API_KEY={s.anthropic_api_key}")
        else:
            lines.append("# ANTHROPIC_API_KEY=")

        if getattr(s, "gemini_api_key", None):
            lines.append(f"GOOGLE_API_KEY={s.gemini_api_key}")
        elif s.llm_provider == "gemini":
            lines.append("# GOOGLE_API_KEY= (set for Gemini)")

        if getattr(s, "openrouter_api_key", None):
            lines.append(f"OPENROUTER_API_KEY={s.openrouter_api_key}")
        elif s.llm_provider == "openrouter":
            lines.append("# OPENROUTER_API_KEY= (set for OpenRouter)")

        if getattr(s, "nvidia_api_key", None):
            lines.append(f"NVIDIA_API_KEY={s.nvidia_api_key}")
        elif s.llm_provider == "nvidia":
            lines.append("# NVIDIA_API_KEY= (set for NVIDIA NIM)")

        lines.append("")

        # Web Dashboard
        lines.append("# Web Dashboard")
        lines.append(f"JWT_SECRET={s.jwt_secret}")
        lines.append(f"ADMIN_PASSWORD={s.admin_password}")
        lines.append(f"WEB_HOST=0.0.0.0")
        lines.append(f"WEB_PORT={s.dashboard_port}")
        lines.append("")

        # Slack
        if s.channels_slack:
            lines.append("# Slack")
            lines.append(f"SLACK_BOT_TOKEN={s.slack_bot_token}")
            lines.append(f"SLACK_APP_TOKEN={s.slack_app_token}")
            lines.append("")

        # Brave API
        if s.brave_api_key:
            lines.append("# Brave Search API")
            lines.append(f"BRAVE_API_KEY={s.brave_api_key}")
            lines.append("")

        # Integrations
        if s.notion_api_key:
            lines.append("# Notion")
            lines.append(f"NOTION_API_KEY={s.notion_api_key}")
            lines.append("")
        if s.todoist_api_key:
            lines.append("# Todoist")
            lines.append(f"TODOIST_API_KEY={s.todoist_api_key}")
            lines.append("")
        if s.linear_api_key:
            lines.append("# Linear")
            lines.append(f"LINEAR_API_KEY={s.linear_api_key}")
            lines.append("")
        if s.spotify_client_id and s.spotify_client_secret:
            lines.append("# Spotify")
            lines.append(f"SPOTIFY_CLIENT_ID={s.spotify_client_id}")
            lines.append(f"SPOTIFY_CLIENT_SECRET={s.spotify_client_secret}")
            lines.append("")

        # Data
        lines.append("# Data")
        lines.append("DATA_DIR=./data")
        lines.append("CHROMADB_PATH=./data/chromadb")
        lines.append("LOG_FILE=./data/logs/aria.log")
        lines.append("")

        # Security
        lines.append("# Security")
        lines.append(f"SECURITY_PROFILE={s.security_profile}")
        lines.append("APPROVAL_TIMEOUT=300")
        lines.append("")

        # Logging
        lines.append("# Logging")
        lines.append("LOG_LEVEL=INFO")
        lines.append("")

        path.write_text("\n".join(lines))

    # ── Helpers ─────────────────────────────────────────────────────────────

    @staticmethod
    def _backup_if_exists(path: Path) -> None:
        """Create a timestamped backup of an existing file."""
        if path.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup = path.with_suffix(f".{timestamp}.bak")
            shutil.copy2(path, backup)
